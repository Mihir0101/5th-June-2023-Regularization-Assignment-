{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57cfcc46-d741-461d-b04a-5eee6abc4777",
   "metadata": {},
   "source": [
    "## **Part 1: Understanding Regularization** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b51bc-8ce0-48a3-9e82-ae2f8ab83b7c",
   "metadata": {},
   "source": [
    "## 1.What is regularization in the context of deep learning? Why is it important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b6ed42-257e-40cd-9315-b52682d4742a",
   "metadata": {},
   "source": [
    "Regularization is a term that we can add to our loss function for reducing overfitting and better feature selection in deep learning.\n",
    "\n",
    "* Importance of the Overfitting\n",
    "\n",
    "1. Prevent Overfitting : Regularization helps the model to perform well on testing data, by preventing the model to learn the noise.\n",
    "\n",
    "2. Generalization : It improves its generalization capabilities.\n",
    "\n",
    "3. Promotes Simplicity : Regularization encourages the simpler models that are easily interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbf155d-db88-40fd-81fc-1101669f1b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caabe452-40e1-4ed2-98d6-1c56d465580d",
   "metadata": {},
   "source": [
    "## 2. Explain the bias-variance tradeoff and how regularization helps in addressing this tradeoff?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3ee896-0680-4446-913f-e391d215e1b8",
   "metadata": {},
   "source": [
    "Bias-variance tradeoff is a fundamental concept of the machine learning which defines the balance between two sources of errors...Bias & Variance. It is crucial to understand this tradeoff for developing generalized model.\n",
    "\n",
    "Bias-Variance Tradeoff :\n",
    "\n",
    "* Bias : Bias refers to the error that is introduced by approximating real-world complex problems with simpler model. Because of the bias model maybe couldn't understand the important relationship between features and targeted variable which can cause the underfitting. Underfitting occurs when model is too simpler to understand the underlying patterns of the data.\n",
    "\n",
    "* Variance : Variance refers to the error that is intorduced by the model's sensitivity towards the small fluctuation in training data.Variance can cause model to learn noise in training data, which can lead the overfitting. Overfitting occurs when the model is too complex and fits the training data well but fails to generalize new data.\n",
    "\n",
    "* How Regularization Helps in Addressing the Bias-Variance Tradeoff :                                                                                                                                                                                                                                                                           \n",
    "\n",
    "L1 and L2 Regularization: These techniques add a penalty term to the loss function that discourages large weights. By constraining the weights, regularization reduces the model's complexity, which helps in mitigating overfitting and thus reducing variance.\n",
    "\n",
    "Dropout: By randomly dropping units (along with their connections) during training, dropout prevents the model from becoming too reliant on specific neurons.\n",
    "\n",
    "This technique monitors the model's performance on a validation set and stops training when performance starts to deteriorate. \n",
    "\n",
    "Controlling Bias : If the regularization strength is too high, it can increase bias by making the model too simple, leading to underfitting. Therefore, choosing the right amount of regularization is crucial to maintaining the balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb63a83e-cf59-4e3e-8cb5-41d6d4785213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de6d1e0b-f54f-4a11-96dd-5480d7669dad",
   "metadata": {},
   "source": [
    "## 3. Describe the concept of L1 and L2 regularization. How do they differ in terms of penalty calculation and their effects on the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b3b56f-7e57-4c87-b479-8315729e5c4b",
   "metadata": {},
   "source": [
    "* **L1 Regularization**\n",
    "\n",
    "L1 Regularization adds the sum of absolute value of model parameters(weights) to the loss function.\n",
    "\n",
    "It is also know as Lasso Regression.\n",
    "\n",
    "Formula : Loss = Original Loss + λi ∑ ∣ wi ∣\n",
    "\n",
    "λ is a regularization parameter that controls the strength of penalty.\n",
    "\n",
    "* **L2 Regularization**\n",
    "\n",
    "L2 Regularization adds the sum of squared values of the model's parameters to the loss function.\\\n",
    "\n",
    "It is also know as the Reidge Regression.\n",
    "\n",
    "Formula : Loss = Original Loss + λi ∑ (wi)**2\n",
    "\n",
    "* **How do they differ in terms of penaly calculation:**\n",
    "\n",
    "L1 uses the absolute value of the weights.\n",
    "\n",
    "L2 uses the squared value of the weights.\n",
    "\n",
    "* **Effects of L1 on Model**\n",
    "\n",
    "L1 Regularization tends to produce sparse models, it means that L1 drives some of the weights to zero. This ability of features selection can be used in mulit-dimensional datasets.\n",
    "\n",
    "It make the model more interpretable because of using fewer parameters.\n",
    "\n",
    "* **Effects of L2 on Model**\n",
    "\n",
    "L2 shrinks the weights towards the zero but not exactly zero. By doing this we retains all features with less effect.\n",
    "\n",
    "L2 Regularization makes the model too smooth by penalizing the large weights.\n",
    "\n",
    "It is tends to produce more stanble model, because it treats all the weights equally and reduces the influence of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b48259d-67ca-43a8-bd36-5063ab56ec07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c15e07b-9ae3-4afb-8a93-5eebd5d8884a",
   "metadata": {},
   "source": [
    "## 4. Discuss the role of regularization in preventing overfitting and improving the generalization of deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6817be1b-08b9-4380-be69-2bac96c832f0",
   "metadata": {},
   "source": [
    "* **Preventing Overfitting**\n",
    "\n",
    "L1 regularization creates the sparse models and L2 shrinks the weights near zero but not-zero. This helps the model to not overfit on trainig data.\n",
    "\n",
    "Regularization helps to smooth the fluctuation and produces more generalized models.\n",
    "\n",
    "Dropout helps in preventing the network to rely on specific neurons.\n",
    "\n",
    "* **Generalization**\n",
    "\n",
    "Batch Normalization acts a regularization which adds noise to the input data for creating the generalized model.\n",
    "\n",
    "By artificially increasing the size of the training set through transformations like rotations, shifts, flips, and zooms, data augmentation exposes the model to a wider variety of inputs. This makes the model more robust to variations and improves its ability to generalize.\n",
    "\n",
    "Early stopping monitors the model’s performance on a validation set and halts training when performance starts to degrade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee16d1-ae00-4253-a75b-fd8cf1f09860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb6ad274-50c0-4721-8593-f23b341a6994",
   "metadata": {},
   "source": [
    "## **Part 2: Regularization Tecpiques**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d2d84e-50cd-4e0e-a339-da9ec717b7f7",
   "metadata": {},
   "source": [
    "## 5. Explain Dropout regularization and how it works to reduce overfitting. Discuss the impact of Dropout on model training and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab12386f-fcac-41ec-8bf6-20800674c362",
   "metadata": {},
   "source": [
    "Droput is a regularization technique used to reduce the overfitting by just randomly 'dropping out' some fraction of neurons to zero during training.\n",
    "\n",
    "* **How dropout works**\n",
    "\n",
    "1. Training Phase : In the training, phase dropout selects the fraction p of neurons to set their value zero. This neurons will not help in neither forward nor backward propagation. Remaining neurons will scaled by 1 / 1 - p to maintain the expected sum of outputs. This scaling ensures that the total input to next layer remain same as it would be without the dropout.\n",
    "\n",
    "2. Inference Phase : Dropout will be not applied to the inference phase.\n",
    "\n",
    "* **Impact of Dropout on Model Trainig and Inference**\n",
    "\n",
    "1. Reduce Overfitting : Dropout drops fraction of neurons to zero, by doing this it prevents the model to rely heavily on specific neurons or fraction of neurons. It will force the model to learn redundant relationships, which makes it more robust and less likely to overfit the training data.\n",
    "\n",
    "2. Robust Feature Learning : It encourages the model to learn more distributed representation of the data. Each neuron must perform well in the context of combination of each neuron, leading to more generalized feature learning.\n",
    "\n",
    "3. Increasing Training Time : Dropout can slow down the convergence speed because model also effectively learns the subnetwork at the same time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c90fd3c-9d66-4069-b9fa-9304d264b14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e22813d2-c608-4371-8da1-1e4b92dba5e8",
   "metadata": {},
   "source": [
    "## 6. Describe the concept of Early stopping as a form of regularization. How does it help prevent overfitting during the training process?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cd8c26-d74f-4cfb-ad8f-cb9473db3c3b",
   "metadata": {},
   "source": [
    "Earlystopping is a regularization technique used to stop the overfitting by monitoring the model's performance on validation set and halting training when model starts to degrade.\n",
    "\n",
    "It is perticularly used in iterative training process.\n",
    "\n",
    "* **How does it helps to prevent overfitting**\n",
    "\n",
    "1. Avoiding Over-Training : Overfitting occurs when model starts to learn specific details of the training data. Earlystopping stops it by halting before model starts to over-train the training data.\n",
    "\n",
    "2. Balancing Bias and Variance : Training the model for few epochs can lead underfitting and too much epochs can cause the overfitting. Earlystopping helps us to find the optimal point where model learned enough to generalize.\n",
    "\n",
    "3. Resources : Because of earlystopping we can save the computations resources by do not training model beyond the point where model is generalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5282430-47db-4470-bd04-3db6bd72f256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "431a41c6-d6ed-46b8-97f9-dc3d586ad756",
   "metadata": {},
   "source": [
    "## 7. Explain the concept of Batch Normalization and its role as a form of regularization. How does Batch Normalization help in preventing overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e407ffb-6ed7-463f-b61f-bd7465d27935",
   "metadata": {},
   "source": [
    "Batch normalization is a technique used to improve the training process by normalizing the input data. It also stabalizes and accelerates the training process makes it easier to train.\n",
    "\n",
    "* **Role as a form of Regularization**\n",
    "\n",
    "1. Reduce Internal Covariate Shift : Internal covariate shift refers the changes in network distribution due to changes in parameters of network. By reducing the inputs, Batch Normalization reduces the shift, stabalizes the learning process and allows the high learning rates.\n",
    "\n",
    "2. Loss Landscape : Batch normalization smooths the loss landscape, making the optimization process more stable and effiecient. This leads to faster convergence and reduces the likelihood of getting stuck in poor local minima.\n",
    "\n",
    "* **How Batch Normalization helps to reduce the overfitting**\n",
    "\n",
    "1. Improved Generalization : By stabelizing the learning process and noise generated through mini batch can help the model generalize.\n",
    "\n",
    "2. Higher Learning Rates : It allows the higher learning rates which speed up the training and also adds the noise in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995be908-cc82-412e-baf4-baaadea14cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3814952f-da64-4dcf-9448-428e85d0353c",
   "metadata": {},
   "source": [
    "## **Part 3: Applying Regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a79972-fc60-4818-8dc4-5129eda8b3e5",
   "metadata": {},
   "source": [
    "## 8. Implement Dropout regularization in a deep learning model using a framework of your choice. Evaluate its impact on model performance and compare it with a model without Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a7d7a5-15db-45fa-9930-6fbd4388f542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=24.3.25\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1\n",
      "  Downloading ml_dtypes-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.28.1)\n",
      "Collecting keras>=3.2.0\n",
      "  Downloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.1)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.65.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=3.10.0\n",
      "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.11)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting tensorboard<2.18,>=2.17\n",
      "  Downloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting optree\n",
      "  Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.7/347.7 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting namex\n",
      "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting rich\n",
      "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.1)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.13.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, opt-einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, optree, markdown-it-py, rich, keras, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.7.0\n",
      "    Uninstalling h5py-3.7.0:\n",
      "      Successfully uninstalled h5py-3.7.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.65.1 h5py-3.11.0 keras-3.4.1 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.0 namex-0.0.8 opt-einsum-3.3.0 optree-0.12.1 rich-13.7.1 tensorboard-2.17.0 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.4.0 typing-extensions-4.12.2 werkzeug-3.0.3 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d6b9958-87f7-4454-ade1-701eee968387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 12:57:43.210773: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-30 12:57:43.215715: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-30 12:57:43.233145: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-30 12:57:43.262630: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-30 12:57:43.271412: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-30 12:57:43.291999: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-30 12:57:44.843990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee16b72b-2863-4473-86b8-274b8569486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c5c7b2-99f6-496f-b16b-1686fb58623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86f7f900-61da-4448-8fd3-a72717089d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid,x_train = x_train[:5000]/255 , x_train[5000:]/255\n",
    "x_test = x_test / 255\n",
    "y_valid,y_train = y_train[:5000] , y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6701aa06-3d83-42e7-93e5-2ded1edcad9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d78f7964-7e8b-4fe8-a6dc-b33ceb98536a",
   "metadata": {},
   "source": [
    "**Model without Dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "738d5e74-1ef4-4089-9cab-e6286cb555ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "LAYERS = [\n",
    "tf.keras.layers.Flatten(input_shape=[28,28]),\n",
    "tf.keras.layers.Dense(300,activation='relu'),\n",
    "tf.keras.layers.Dense(110,activation='relu'),\n",
    "tf.keras.layers.Dense(10,activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f360b60b-9090-4d00-bba0-57d1aeaea990",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65052e0e-829b-473c-8d00-bbbed86e18b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed149ad4-02aa-4c62-9a27-840e4e868cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8911 - loss: 0.3694 - val_accuracy: 0.9686 - val_loss: 0.1082\n",
      "Epoch 2/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9743 - loss: 0.0838 - val_accuracy: 0.9718 - val_loss: 0.0889\n",
      "Epoch 3/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9810 - loss: 0.0571 - val_accuracy: 0.9748 - val_loss: 0.0912\n",
      "Epoch 4/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0414 - val_accuracy: 0.9764 - val_loss: 0.0796\n",
      "Epoch 5/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0327 - val_accuracy: 0.9790 - val_loss: 0.0760\n",
      "Epoch 6/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0226 - val_accuracy: 0.9788 - val_loss: 0.0834\n",
      "Epoch 7/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0206 - val_accuracy: 0.9784 - val_loss: 0.0853\n",
      "Epoch 8/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0206 - val_accuracy: 0.9820 - val_loss: 0.0786\n",
      "Epoch 9/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0174 - val_accuracy: 0.9814 - val_loss: 0.0822\n",
      "Epoch 10/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0130 - val_accuracy: 0.9796 - val_loss: 0.0977\n",
      "Epoch 11/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9958 - loss: 0.0123 - val_accuracy: 0.9832 - val_loss: 0.0936\n",
      "Epoch 12/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0134 - val_accuracy: 0.9808 - val_loss: 0.0995\n",
      "Epoch 13/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0100 - val_accuracy: 0.9828 - val_loss: 0.0848\n",
      "Epoch 14/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0103 - val_accuracy: 0.9836 - val_loss: 0.0930\n",
      "Epoch 15/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0062 - val_accuracy: 0.9822 - val_loss: 0.1106\n",
      "Epoch 16/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0125 - val_accuracy: 0.9828 - val_loss: 0.1087\n",
      "Epoch 17/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0091 - val_accuracy: 0.9792 - val_loss: 0.1216\n",
      "Epoch 18/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0087 - val_accuracy: 0.9808 - val_loss: 0.1200\n",
      "Epoch 19/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0092 - val_accuracy: 0.9766 - val_loss: 0.1380\n",
      "Epoch 20/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0113 - val_accuracy: 0.9818 - val_loss: 0.1098\n",
      "Epoch 21/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0078 - val_accuracy: 0.9774 - val_loss: 0.1515\n",
      "Epoch 22/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0101 - val_accuracy: 0.9818 - val_loss: 0.1194\n",
      "Epoch 23/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0039 - val_accuracy: 0.9820 - val_loss: 0.1349\n",
      "Epoch 24/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0083 - val_accuracy: 0.9826 - val_loss: 0.1208\n",
      "Epoch 25/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0060 - val_accuracy: 0.9838 - val_loss: 0.1087\n",
      "Epoch 26/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0069 - val_accuracy: 0.9834 - val_loss: 0.1371\n",
      "Epoch 27/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0074 - val_accuracy: 0.9822 - val_loss: 0.1513\n",
      "Epoch 28/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0081 - val_accuracy: 0.9814 - val_loss: 0.1365\n",
      "Epoch 29/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0079 - val_accuracy: 0.9852 - val_loss: 0.1254\n",
      "Epoch 30/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0065 - val_accuracy: 0.9828 - val_loss: 0.1395\n",
      "Epoch 31/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0058 - val_accuracy: 0.9822 - val_loss: 0.1537\n",
      "Epoch 32/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 0.9776 - val_loss: 0.1777\n",
      "Epoch 33/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0054 - val_accuracy: 0.9822 - val_loss: 0.1471\n",
      "Epoch 34/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0069 - val_accuracy: 0.9832 - val_loss: 0.1516\n",
      "Epoch 35/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9979 - loss: 0.0073 - val_accuracy: 0.9846 - val_loss: 0.1358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f1acb7fbfd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=35,validation_data=(x_valid,y_valid),batch_size=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0cb9585-b36e-4fb8-883e-0a97c0e9f113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9778 - loss: 0.1984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15403403341770172, 0.9814000129699707]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6aaa2d-aaa3-4430-b20c-769174923a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9eb6c15-1fcf-43d2-8e88-272c5898cb83",
   "metadata": {},
   "source": [
    "**Model with Dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b57a1cbf-d931-4e87-a0ed-f272853052a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS_DROPOUT = [\n",
    "tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "tf.keras.layers.Dropout(0.3),\n",
    "tf.keras.layers.Dense(300,activation='relu'),\n",
    "tf.keras.layers.Dropout(0.10),\n",
    "tf.keras.layers.Dense(110,activation='relu'),\n",
    "tf.keras.layers.Dense(10,activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67f3e900-993b-448c-b8d7-ae670413ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout = tf.keras.models.Sequential(LAYERS_DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "486e4e0f-8eb8-4d68-a139-d3a5b61236cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0c137c8-0472-4353-bf1f-5051314a6b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8487 - loss: 0.4848 - val_accuracy: 0.9614 - val_loss: 0.1253\n",
      "Epoch 2/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9510 - loss: 0.1540 - val_accuracy: 0.9728 - val_loss: 0.0879\n",
      "Epoch 3/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9646 - loss: 0.1151 - val_accuracy: 0.9784 - val_loss: 0.0708\n",
      "Epoch 4/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9682 - loss: 0.0990 - val_accuracy: 0.9798 - val_loss: 0.0698\n",
      "Epoch 5/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9744 - loss: 0.0796 - val_accuracy: 0.9768 - val_loss: 0.0759\n",
      "Epoch 6/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9754 - loss: 0.0760 - val_accuracy: 0.9798 - val_loss: 0.0675\n",
      "Epoch 7/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9763 - loss: 0.0730 - val_accuracy: 0.9836 - val_loss: 0.0592\n",
      "Epoch 8/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9795 - loss: 0.0634 - val_accuracy: 0.9834 - val_loss: 0.0578\n",
      "Epoch 9/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9793 - loss: 0.0622 - val_accuracy: 0.9794 - val_loss: 0.0714\n",
      "Epoch 10/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9819 - loss: 0.0563 - val_accuracy: 0.9844 - val_loss: 0.0523\n",
      "Epoch 11/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9807 - loss: 0.0566 - val_accuracy: 0.9852 - val_loss: 0.0588\n",
      "Epoch 12/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9832 - loss: 0.0501 - val_accuracy: 0.9846 - val_loss: 0.0573\n",
      "Epoch 13/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9838 - loss: 0.0485 - val_accuracy: 0.9830 - val_loss: 0.0602\n",
      "Epoch 14/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9841 - loss: 0.0497 - val_accuracy: 0.9852 - val_loss: 0.0567\n",
      "Epoch 15/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9859 - loss: 0.0426 - val_accuracy: 0.9830 - val_loss: 0.0586\n",
      "Epoch 16/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9856 - loss: 0.0444 - val_accuracy: 0.9846 - val_loss: 0.0607\n",
      "Epoch 17/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9861 - loss: 0.0429 - val_accuracy: 0.9822 - val_loss: 0.0644\n",
      "Epoch 18/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9857 - loss: 0.0435 - val_accuracy: 0.9856 - val_loss: 0.0573\n",
      "Epoch 19/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9857 - loss: 0.0430 - val_accuracy: 0.9830 - val_loss: 0.0717\n",
      "Epoch 20/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9857 - loss: 0.0418 - val_accuracy: 0.9836 - val_loss: 0.0612\n",
      "Epoch 21/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9870 - loss: 0.0392 - val_accuracy: 0.9838 - val_loss: 0.0600\n",
      "Epoch 22/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9878 - loss: 0.0364 - val_accuracy: 0.9854 - val_loss: 0.0588\n",
      "Epoch 23/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9880 - loss: 0.0352 - val_accuracy: 0.9852 - val_loss: 0.0569\n",
      "Epoch 24/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9883 - loss: 0.0347 - val_accuracy: 0.9854 - val_loss: 0.0635\n",
      "Epoch 25/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9876 - loss: 0.0348 - val_accuracy: 0.9860 - val_loss: 0.0599\n",
      "Epoch 26/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9872 - loss: 0.0387 - val_accuracy: 0.9844 - val_loss: 0.0637\n",
      "Epoch 27/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9894 - loss: 0.0317 - val_accuracy: 0.9844 - val_loss: 0.0636\n",
      "Epoch 28/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9874 - loss: 0.0366 - val_accuracy: 0.9826 - val_loss: 0.0655\n",
      "Epoch 29/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9897 - loss: 0.0331 - val_accuracy: 0.9836 - val_loss: 0.0637\n",
      "Epoch 30/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9888 - loss: 0.0351 - val_accuracy: 0.9858 - val_loss: 0.0633\n",
      "Epoch 31/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9891 - loss: 0.0340 - val_accuracy: 0.9844 - val_loss: 0.0735\n",
      "Epoch 32/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9898 - loss: 0.0335 - val_accuracy: 0.9842 - val_loss: 0.0689\n",
      "Epoch 33/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9901 - loss: 0.0325 - val_accuracy: 0.9856 - val_loss: 0.0697\n",
      "Epoch 34/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9893 - loss: 0.0327 - val_accuracy: 0.9848 - val_loss: 0.0657\n",
      "Epoch 35/35\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9887 - loss: 0.0348 - val_accuracy: 0.9842 - val_loss: 0.0689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f1aac226aa0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dropout.fit(x_train,y_train,validation_data=(x_valid,y_valid),epochs=35,batch_size=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fde4690d-26a5-477a-b6cf-c098b39bafb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06795641034841537, 0.984499990940094]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dropout.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a1c057-0f6f-447c-9567-06fce56c91a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "517dde33-4300-49c1-98f9-513bdddc2dd4",
   "metadata": {},
   "source": [
    "**Accuracy on Testing Data without Dropout = 0.9778**\n",
    "\n",
    "**Accuracy on Testing Data with Dropout = 0.9816**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705cfed-cab0-480b-8aba-0a5f6be08e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f188d2c7-9f9b-4f67-b7e4-056e7803c0ca",
   "metadata": {},
   "source": [
    "## 9. Discuss the considerations and tradeoffs when choosing the appropriate regularization technique for a given deep learning task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ee9e78-7313-43b2-b818-5cebdc49f56f",
   "metadata": {},
   "source": [
    "**Considerations**\n",
    "\n",
    "1. Nature of Data : High dimensional data may benefit by L1 Regularization and noisy data may benefit by Dropout.\n",
    "\n",
    "2. Model Complexity : Complex models are more prone to overfitting and thus may requires more stronger regularization.\n",
    "\n",
    "3. Computational Resource : Techniques like Dropout and batch normalization increases the training time. Consider the model generalization justifies the additional computational cost.\n",
    "\n",
    "4. Performance Metrics : L1 helps to create sparse models which are easily interpretable and l2 leads to smoother models.\n",
    "\n",
    "**Tradeoff**\n",
    "\n",
    "1. L1 and L2 Regularization :\n",
    "\n",
    "L1 regularization tends to produce sparse models, which can be beneficial for feature selection and interpretability but may result in less smooth solutions.\n",
    "\n",
    "L2 regularization encourages smaller weights, leading to smoother models and often better performance on unseen data but may not provide sparsity.\n",
    "\n",
    "2. Dropout :\n",
    "\n",
    "Dropout introduces noise during training by randomly dropping neurons. This can improve generalization but may require longer training times and careful tuning of the dropout rate.\n",
    "\n",
    "3. Batch Normalization :\n",
    "\n",
    "Batch normalization helps stabilize and accelerate training, allowing for higher learning rates. However, it adds computational overhead and complexity.\n",
    "\n",
    "4. Early Stopping :\n",
    "\n",
    "Early stopping can save computational resources by halting training once performance on the validation set stops improving. However, it requires careful monitoring and may not always capture the best model if validation performance fluctuates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a233a9-b73e-449b-b766-338f085e5255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
